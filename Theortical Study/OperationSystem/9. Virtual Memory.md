# Virtual Memory
- 물리적인 메모리는 운영체제가 관여하지 않지만, 가상 메모리의 경우에는 전적으로 운영체제가 관여하게 된다
## Demand Paging
- 실제로 필요할 때 page를 메모리에 올리는 것
  - i/o 양 감소
  - memory 사용 감소
  - 빠른 응답 시간
  - 사용자 수용 더 많이 가능
- valid / invalid bit 사용 시
  - invalid의 경우 
    - 사용되지 않는 주소 영역
    - 페이지가 물리적 장소에 위치하지 않을 경우
  - 이 bit를 활용하여 빠르게 page fault라는 현상을 반환
  - cpu가 자동적으로 운영체제로 전환되게 된다
### Page fault
- invalid 하면 MMU가 trap 발생 시킴
- page fault handler 가 실행됨
- 일련의 처리 순서에 맞추어 page fault 처리
- page fault rate에 따라 memory access time 이 상당히 차이가 나게 된다
- 이러한 percent를 줄이는 것이 중요하다(page fault는 상당히 긴 절차를 진행하게 되므로)
#### 빈 페이지가 없다면 (page replacement)
- free frame 이 없다면 
- replacement Algorithm 으로 처리
- 해당 데이터를 baking으로 쫓아내고, 다시 swap 해주는 과정을 거치게 된다 (또한, page table 의 valid bit 를 변환)
#### Replacement Algorithm
##### Optimal Algorithm (min, opt)
- 참조되는 page를 미리 알고있다는 가정 하에 진행을 하게 된다
- 가장 먼 미래에 참조되는 페이지를 쫓아내게 된다
- 그렇다면 어떻게 미래를 아는가?
  - Offline Algorithm 이기에 (실제 가 아니다)
- 다른 알고리즘의 upper bound 제공을 하는 기준이 된다 (참고용)
##### FIFO Algorithm
- 선입 선출
- FIFO Anomaly (Belady's Anomaly)
  - 더 많은 프레임이 오히려 page falut를 발생시킬 수 있다

##### LRU(least recently used) Algorithm
- 가장 오래전에 참조된 것을 지움
- 즉, 먼저 들어왔어도 최근에 참조되었다면 남아있게 된다

##### LFU (Least Frequently Used) Algorithm
- 참조 횟수가 가장 적은 페이지를 지움
- 만약 여럿이 있다면 
  - 임의 선정
  - 좀 더 성능향상을 위해 가장 오래전 참조된 page를 선택할 수도 있다
- page의 인기도를 좀 더 반영하게 된다
- 최근성은 반영 못함
- LRU 보다 복잡 
##### LRU 와 LFU 간의 비교
- LRU는 마지막 참조만을(과거를 생각 하지 않음)
- LFU는 과거만을 보게 된다(최근은 고려하는 것이 적음)
- LRU : 리스트 형태로 구현
  - 재 참조시 꼬리에 다시 넣어줌
  - 새로운 참조 등장이면 머리를 없애고 꼬리에 새로운 친구를 넣어줌
  - O(1) 으로
- LFU : 참조 횟수를 모두에게 비교해가며 진행
  - 힙으로 구현하게 된다
  - 모두 비교하면 O(n), 힙이면 O(log n) 의 복잡도 가지게 됨
  - 이진트리의 구조를 갖게 된다

##### 다양한 caching 환경
- 캐슁 기법
  - 한정된 공간에 요청된 데이터를 저장해 두었다가 캐쉬로부터 직접 서비스 하는 방식
  - paging, cache, buffer, web 등 다양한 분야에서 활용
- 캐쉬에서의 시간의 제약
  - 교체 알고리즘에서 삭제할 항목을 결정하는데 많은 시간을 줄 수 없음 (최대 O(log n) 까지만 허용, paging은 O(1)조차 불가능 한 경우도 발생)
  - 따라서 paging에서는 LRU, LFU 사용 불가능
##### Clock Algorithm
- LRU의 근사 알고리즘
- NRU (Not Recently Used) 라고도 불림
- 시계 형태의 이미지로 쉽게 설명될 수 있다
- 포인터가 이동하게 되고, reference bit 가 0인것을 찾게 된다
- 1인 친구들은 전부 0으로 전환하며 진행한다
- reference bit 전환은 hardware가 대신하게 된다
- modified bit 또한 참조 가능
  - backing store에서 올라올 때, 수정여부를 저장
  - backing store에 재저장 여부를 결정하게 된다
### Page Frame Allocation
- 각 process 에 얼마만큼의 page frame을 할당할 것인가?
- 여러 페이지를 동시 참조할 수 있고
- loop 에서의 page들은 한꺼번에 할당하는 것이 유리하다
- Sheme
  - Equal : 같은 갯수 할당
  - Proportional: 크기에 비례하여 할당
  - Priority : 우선선위에 따라 할당

#### Global vs Local
- global = 할당 시 다른 frame를 빼앗아 올 수 있다 / 전체 통일된 알고리즘 활용 (경쟁)
- local = 자신 내의 frame 내에서만 replament / process 별로 별도 알고리즘 가능 (미리)

#### Thrashing
- 최소한의 page frame을 할당받지 못한 경우 발생한다
- 메모리 할당 프로그램들이 너무 많다면, cpu utilization 이 갑자기 극도로 낮아진다
- page fault 가 빈번히 발생하여 cpu util 이 낮아지게 되는 것이다
- 즉, 프로그램 별 메모리 할당 용량이 너무 작다는 것이다
- 이러면 운영체제는 오히려 프로그램을 더 많이 올려버리고, thrashing이 반복해서 유지된다
- 따라서 메모리 내 프로그램 숫자를 조절하는 것이다
##### Working-set Model
- Locality of reference
  - 특정 시간동안 프로세스는 일정장소만을 집중적으로 참조한다
  - 해당 페이지들을 locality set이라 함
- 이렇듯 해당 프로세스가 원할하게 진행되기 위해 메모리에 올라와야 할 프로세스들을 working set이라고 정의하게 된다
- prcess별 working set을 할당해 주고, 수행되지 않는 다면 swap out(suspend) 를 하게 되는 부분이다
- 이를 통해 Thrashing을 방지할 수 있다
- 